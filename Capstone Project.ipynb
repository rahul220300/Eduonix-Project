{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8495e6e9",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee94e5ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, accuracy_score, roc_curve, auc\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Set plot style\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#Step 1: Setup and Import Necessary Libraries\n",
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd           \n",
    "import numpy as np           \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns        \n",
    "\n",
    "#Additional libraries for machine learning\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.linear_model import LogisticRegressions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "#Step 2: Import the Dataset\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Dentistry Dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n",
    "\n",
    "\n",
    "#Step 3: Data Preprocessing\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode the 'Gender' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "\n",
    "# Display the unique values in the 'Gender' column\n",
    "df['Gender'].unique()\n",
    "\n",
    "# Define the independent variables (features) and the dependent variable (target)\n",
    "X = df.drop(['Sl No', 'Sample ID', 'Gender'], axis=1)\n",
    "y = df['Gender']\n",
    "\n",
    "# Normalize the independent variables\n",
    "normalizer = Normalizer()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "                                        \n",
    "# 4: Exploratory Data Analysis\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "#Step 5: Model Building\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the Logistic Regression model\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "logistic_accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f'Logistic Regression Accuracy: {logistic_accuracy}')\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the Decision Tree Classifier\n",
    "y_pred_tree = decision_tree_model.predict(X_test)\n",
    "tree_accuracy = accuracy_score(y_test, y_pred_tree)\n",
    "print(f'Decision Tree Classifier Accuracy: {tree_accuracy}')\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the Random Forest Classifier\n",
    "y_pred_forest = random_forest_model.predict(X_test)\n",
    "forest_accuracy = accuracy_score(y_test, y_pred_forest)\n",
    "print(f'Random Forest Classifier Accuracy: {forest_accuracy}')\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the XGBoost Classifier\n",
    "y_pred_xgboost = xgboost_model.predict(X_test)\n",
    "xgboost_accuracy = accuracy_score(y_test, y_pred_xgboost)\n",
    "print(f'XGBoost Classifier Accuracy: {xgboost_accuracy}')\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the XGBoost Classifier\n",
    "y_pred_xgboost = xgboost_model.predict(X_test)\n",
    "xgboost_accuracy = accuracy_score(y_test, y_pred_xgboost)\n",
    "print(f'XGBoost Classifier Accuracy: {xgboost_accuracy}')\n",
    "\n",
    "#Step 6: Model \n",
    "\n",
    "# Define a function to plot ROC curve\n",
    "def plot_roc_curve(y_test, y_pred, model_name):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic - {model_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "print(f'Logistic Regression Confusion Matrix:\\n{conf_matrix_logistic}')\n",
    "plot_roc_curve(y_test, y_pred_logistic, 'Logistic Regression')\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "conf_matrix_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "print(f'Decision Tree Confusion Matrix:\\n{conf_matrix_tree}')\n",
    "plot_roc_curve(y_test, y_pred_tree, 'Decision Tree')\n",
    "\n",
    "# Evaluate Random Forest\n",
    "conf_matrix_forest = confusion_matrix(y_test, y_pred_forest)\n",
    "print(f'Random Forest Confusion Matrix:\\n{conf_matrix_forest}')\n",
    "plot_roc_curve(y_test, y_pred_forest, 'Random Forest')\n",
    "\n",
    "# Evaluate XGBoost\n",
    "conf_matrix_xgboost = confusion_matrix(y_test, y_pred_xgboost)\n",
    "print(f'XGBoost Confusion Matrix:\\n{conf_matrix_xgboost}')\n",
    "plot_roc_curve(y_test, y_pred_xgboost, 'XGBoost')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a9164",
   "metadata": {},
   "source": [
    "1.Project Title and Description: A brief overview of what the project is about and its goals.\n",
    "2.Dataset Information: Information about the dataset, including the columns and how the data was prepared.\n",
    "3.Exploratory Data Analysis: Important findings from analyzing the data, including a heatmap showing correlations.\n",
    "4.Model Building: Details about the machine learning models used and how well they performed.\n",
    "5.Model Evaluation: Metrics and visualizations to evaluate the models, like confusion matrices and ROC curves.\n",
    "6.Conclusion: A summary of the results and suggestions for future improvements.\n",
    "Summary\n",
    "This project shows how dental metrics can be used to predict gender with different machine learning models. The steps include data preparation, analysis, model building, and evaluation. The best model is chosen based on accuracy and ROC-AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29678d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
